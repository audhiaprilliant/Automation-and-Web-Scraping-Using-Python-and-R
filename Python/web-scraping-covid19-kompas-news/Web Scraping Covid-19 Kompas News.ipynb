{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As references, I used following sites:\n",
    "[**Real Python 1**](https://realpython.com/python-web-scraping-practical-introduction/) and [**Real Python 2**](https://realpython.com/beautiful-soup-web-scraper-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:56:17.115829Z",
     "start_time": "2020-06-13T11:56:09.709697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modules for web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Module for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Module for regular expression\n",
    "import re\n",
    "\n",
    "# Module for file management\n",
    "import os\n",
    "\n",
    "# Module for timing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:56:18.427726Z",
     "start_time": "2020-06-13T11:56:18.422033Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = os.getcwd()\n",
    "startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:56:22.197218Z",
     "start_time": "2020-06-13T11:56:20.558892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the url\n",
    "url = 'https://www.kompas.com/covid-19'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:56:23.826418Z",
     "start_time": "2020-06-13T11:56:23.597115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Wrangling HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "job_elems = soup.find_all('div',class_='covid__box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:56:24.842980Z",
     "start_time": "2020-06-13T11:56:24.822933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the date\n",
    "date_scrape = soup.find('span',class_='covid__date').text\n",
    "date_scrape = re.findall(r'Update terakhir: (\\S+.+WIB)',date_scrape)[0].replace(', ',',')\n",
    "date = date_scrape.split(',')[0]\n",
    "time = date_scrape.split(',')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:57:27.042795Z",
     "start_time": "2020-06-13T11:57:27.025158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Date manipulation\n",
    "dict_month = {'Januari':'01','Februari':'02','Maret':'03','April':'04','Mei':'05','Juni':'06','Juli':'07',\n",
    "              'Agustus':'08','September':'09','Oktober':'10','November':'11','Desember':'12'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = re.findall(r'\\w+',date)[0]\n",
    "month_format = re.findall(r'\\w+',date)[1]\n",
    "year_format = re.findall(r'\\w+',date)[2]\n",
    "# If condition\n",
    "if len(date_format) == 1:\n",
    "    date_format = '0' + date_format\n",
    "else:\n",
    "    date_format = date_format\n",
    "date = year_format+'/'+dict_month.get(month_format)+'/'+date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:57:29.601893Z",
     "start_time": "2020-06-13T11:57:29.539670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get summary\n",
    "\n",
    "# Regular expression pattern\n",
    "pattern_summary = re.compile(r'\\d[^\\s]+')\n",
    "\n",
    "for job_elem in soup.find_all('div',class_='covid__box'):\n",
    "    # Each job_elem is a new BeautifulSoup object.\n",
    "    terkonfirmasi_elem = job_elem.find('div',class_='covid__box2 -cases')\n",
    "    dirawat_elem = job_elem.find('div',class_='covid__box2 -odp')\n",
    "    meninggal_elem = job_elem.find('div',class_='covid__box2 -gone')\n",
    "    sembuh_elem = job_elem.find('div',class_='covid__box2 -health')\n",
    "    # Daily update\n",
    "    a = pattern_summary.findall(terkonfirmasi_elem.text)[0].replace(',','')\n",
    "    b = pattern_summary.findall(dirawat_elem.text)[0].replace(',','')\n",
    "    c = pattern_summary.findall(meninggal_elem.text)[0].replace(',','')\n",
    "    d = pattern_summary.findall(sembuh_elem.text)[0].replace(',','')\n",
    "    daily_update = ','.join([date,time,a,b,c,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:02:47.880656Z",
     "start_time": "2020-06-13T12:02:47.869399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020/06/13,16:53 WIB,37420,21553,2091,13776'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:27:06.952150Z",
     "start_time": "2020-05-10T08:27:06.797662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has not been updated yet!\n"
     ]
    }
   ],
   "source": [
    "with open(dir_path+'/'+'Datasets/summary_covid19.txt','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    last_line = lines[-1]\n",
    "    if last_line.split(',')[0] == daily_update.split(',')[0]:\n",
    "        print('----- Summary Data -----')\n",
    "        print('The data has not been updated yet!')\n",
    "        print('Last update:',re.findall(r'^(.+?),',last_line)[0])\n",
    "    else:\n",
    "        with open(dir_path+'/'+'Datasets/summary_covid19.txt','a+') as ff:\n",
    "            ff.write('\\n{}'.format(daily_update))\n",
    "            print('----- Summary Data -----')\n",
    "            print('The data has been updated successfully!')\n",
    "            print('Up to date data:', re.findall(r'^(.+?),',daily_update)[0])\n",
    "            ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:27:11.182271Z",
     "start_time": "2020-05-10T08:27:10.832931Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get summary - provinsi\n",
    "\n",
    "# Regular expression pattern\n",
    "pattern_prov = re.compile(r'\\d+')\n",
    "\n",
    "provinsi = []\n",
    "terkonfirmasi_prov = []\n",
    "meninggal_prov = []\n",
    "sembuh_prov = []\n",
    "\n",
    "for elem in soup.find_all('div',class_='covid__row'):\n",
    "    provinsi_elem = elem.find('div',class_='covid__prov')\n",
    "    terkonfirmasi_elem = elem.find('span',class_='-odp')\n",
    "    meninggal_elem = elem.find('span',class_='-gone')\n",
    "    sembuh_elem = elem.find('span',class_='-health')\n",
    "    # Append to list    \n",
    "    provinsi.append(provinsi_elem.text)\n",
    "    terkonfirmasi_prov.append(pattern_prov.findall(terkonfirmasi_elem.text)[0])\n",
    "    meninggal_prov.append(pattern_prov.findall(meninggal_elem.text)[0])\n",
    "    sembuh_prov.append(pattern_prov.findall(sembuh_elem.text)[0])\n",
    "\n",
    "# Create dataframe\n",
    "dic_data = {'date':[date]*len(provinsi),'time':[time]*len(provinsi),'provinsi':provinsi,\n",
    "            'confirmed':terkonfirmasi_prov,'deaths':meninggal_prov,'recovered':sembuh_prov}\n",
    "df = pd.DataFrame(data=dic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:27:13.664434Z",
     "start_time": "2020-05-10T08:27:13.345065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has not been updated yet!\n"
     ]
    }
   ],
   "source": [
    "with open(dir_path+'/'+'Datasets/daily_update_covid.csv','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    last_line = lines[-1]\n",
    "    if re.findall(r'^(.+?),',last_line)[0] == df['date'].unique().tolist()[0]:\n",
    "        print('----- Provinces Data -----')\n",
    "        print('The data has not been updated yet!')\n",
    "        print('Last update:',re.findall(r'^(.+?),',last_line)[0])\n",
    "    else:\n",
    "        with open(dir_path+'/'+'Datasets/daily_update_covid.csv','a') as ff:\n",
    "            df.to_csv(ff,header=False,index=False)\n",
    "            print('----- Provinces Data -----')\n",
    "            print('The data has been updated successfully!')\n",
    "            print('Up to date data:', df['date'].unique().tolist()[0])\n",
    "            print(df.head())\n",
    "            ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:38:02.440082Z",
     "start_time": "2020-05-10T08:38:02.432940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program is done in 0:00:36.304477\n"
     ]
    }
   ],
   "source": [
    "print('Program is done in', datetime.now() - startTime,'\n",
    "')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
